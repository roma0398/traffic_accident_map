{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from deeppavlov import configs, build_model, train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/post_data.csv')\n",
    "data = data.dropna()\n",
    "data = data.reset_index()\n",
    "data.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2022-04-07 13:36:12\n",
       "1         2022-04-07 13:00:01\n",
       "2         2022-04-07 12:34:35\n",
       "3         2022-04-07 10:54:30\n",
       "4         2022-04-07 10:46:36\n",
       "                 ...         \n",
       "145016    2014-03-21 06:29:38\n",
       "145017    2014-03-21 06:27:02\n",
       "145018    2014-03-21 03:20:23\n",
       "145019    2014-03-20 22:53:32\n",
       "145020    2014-03-20 22:17:27\n",
       "Name: date, Length: 145021, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16549232</td>\n",
       "      <td>2022-04-07 13:36:12</td>\n",
       "      <td>–•–æ—á–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Ç–∞–∫–∏–º –≤–æ–¥–∏—Ç–µ–ª—è–º...\\n–ß—Ç–æ –¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16549142</td>\n",
       "      <td>2022-04-07 13:00:01</td>\n",
       "      <td>–í –°–∞–Ω–∫—Ç‚Äî–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ –∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –¢–µ–ª–µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16549056</td>\n",
       "      <td>2022-04-07 12:34:35</td>\n",
       "      <td>–ì—Ä—É–∑–æ–≤–∏–∫ –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–ª –Ω–∞–ª–µ–≤–æ —Å–æ  –°—Ç–∞—Ä–æ–¥–µ—Ä–µ–≤–µ–Ω—Å–∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16548757</td>\n",
       "      <td>2022-04-07 10:54:30</td>\n",
       "      <td>–°–µ–≥–æ–¥–Ω—è —É—Ç—Ä–æ–º –ø–æ –∞–¥—Ä–µ—Å—É –ü–æ–ª—é—Å—Ç—Ä–æ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16548729</td>\n",
       "      <td>2022-04-07 10:46:36</td>\n",
       "      <td>–ù–∞ –°–∏—Ç—Ü–µ–≤–æ–π –ø–æ–ª–æ–∂–∏–ª–∏ –∞—Å—Ñ–∞–ª—å—Ç, –∑–∞–¥–µ–ª–∞–≤ –æ–≥—Ä–æ–º–Ω—ã–µ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 date  \\\n",
       "0  16549232  2022-04-07 13:36:12   \n",
       "1  16549142  2022-04-07 13:00:01   \n",
       "2  16549056  2022-04-07 12:34:35   \n",
       "3  16548757  2022-04-07 10:54:30   \n",
       "4  16548729  2022-04-07 10:46:36   \n",
       "\n",
       "                                                text  \n",
       "0  –•–æ—á–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Ç–∞–∫–∏–º –≤–æ–¥–∏—Ç–µ–ª—è–º...\\n–ß—Ç–æ –¥...  \n",
       "1  –í –°–∞–Ω–∫—Ç‚Äî–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ –∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –¢–µ–ª–µ...  \n",
       "2  –ì—Ä—É–∑–æ–≤–∏–∫ –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–ª –Ω–∞–ª–µ–≤–æ —Å–æ  –°—Ç–∞—Ä–æ–¥–µ—Ä–µ–≤–µ–Ω—Å–∫...  \n",
       "3  –°–µ–≥–æ–¥–Ω—è —É—Ç—Ä–æ–º –ø–æ –∞–¥—Ä–µ—Å—É –ü–æ–ª—é—Å—Ç—Ä–æ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç...  \n",
       "4  –ù–∞ –°–∏—Ç—Ü–µ–≤–æ–π –ø–æ–ª–æ–∂–∏–ª–∏ –∞—Å—Ñ–∞–ª—å—Ç, –∑–∞–¥–µ–ª–∞–≤ –æ–≥—Ä–æ–º–Ω—ã–µ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[:11273]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using deepPavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 22:41:14.137 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/0.16/ner/ner_rus_bert_torch.tar.gz download because of matching hashes\n",
      "[nltk_data] Downloading package punkt to /home/caymz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/caymz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/caymz/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/caymz/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2022-04-20 22:41:21.529 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/caymz/.deeppavlov/models/ner_rus_bert_torch/tag.dict]\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-04-20 22:41:26.820 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 360: Load path /home/caymz/.deeppavlov/models/ner_rus_bert_torch/model is given.\n",
      "2022-04-20 22:41:26.824 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 367: Load path /home/caymz/.deeppavlov/models/ner_rus_bert_torch/model.pth.tar exists.\n",
      "2022-04-20 22:41:26.825 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 368: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-04-20 22:41:26.826 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 371: Loading weights from /home/caymz/.deeppavlov/models/ner_rus_bert_torch/model.pth.tar.\n",
      "2022-04-20 22:41:36.280 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
      " BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "config_path = \"/home/caymz/Code/traffic_accident_map-master/notebooks/ner_rus_bert_torch.json\"\n",
    "ner_model = build_model(config_path, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 21:04:17.459 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/0.16/ner/ner_rus_bert_torch.tar.gz download because of matching hashes\n",
      "2022-04-20 21:04:17.528 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/collection3_v2.tar.gz to /home/caymz/.deeppavlov/downloads/total_rus/collection3_v2.tar.gz\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 877k/877k [00:00<00:00, 3.18MB/s]\n",
      "2022-04-20 21:04:18.232 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /home/caymz/.deeppavlov/downloads/total_rus/collection3_v2.tar.gz archive into /home/caymz/.deeppavlov/downloads/total_rus\n",
      "2022-04-20 21:04:22.694 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: TorchTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
      "2022-04-20 21:04:30.496 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/caymz/.deeppavlov/models/ner_rus_bert_torch/tag.dict]\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-04-20 21:04:35.774 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 360: Load path /home/caymz/.deeppavlov/models/ner_rus_bert_torch/model is given.\n",
      "2022-04-20 21:04:35.775 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 367: Load path /home/caymz/.deeppavlov/models/ner_rus_bert_torch/model.pth.tar exists.\n",
      "2022-04-20 21:04:35.776 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 368: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-04-20 21:04:35.777 INFO in 'deeppavlov.models.torch_bert.torch_transformers_sequence_tagger'['torch_transformers_sequence_tagger'] at line 371: Loading weights from /home/caymz/.deeppavlov/models/ner_rus_bert_torch/model.pth.tar.\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(config_path, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['–•–æ—á–µ—Ç—Å—è',\n",
       "   '–æ–±—Ä–∞—Ç–∏—Ç—å—Å—è',\n",
       "   '–∫',\n",
       "   '—Ç–∞–∫–∏–º',\n",
       "   '–≤–æ–¥–∏—Ç–µ–ª—è–º',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   '\\n',\n",
       "   '–ß—Ç–æ',\n",
       "   '–¥–≤–∏–∂–µ—Ç',\n",
       "   '–≤–∞–º–∏',\n",
       "   '–Ω–∞',\n",
       "   '–ø—É—Å—Ç–æ–π',\n",
       "   '–¥–æ—Ä–æ–≥–µ',\n",
       "   '?',\n",
       "   '–î–≤–∞–∂–¥—ã',\n",
       "   '–Ω–∞',\n",
       "   '–∫—Ä–∞—Å–Ω—ã–π',\n",
       "   '–∑–∞',\n",
       "   '1',\n",
       "   '–º–∏–Ω—É—Ç—É',\n",
       "   'ü§¶',\n",
       "   'üèª',\n",
       "   '\\u200d',\n",
       "   '‚ôÇ',\n",
       "   '\\n',\n",
       "   '–¢–∞–∫–æ–π',\n",
       "   '–±–µ—Å–ø—Ä–µ–¥–µ–ª',\n",
       "   '–Ω–∞',\n",
       "   '–¥–æ—Ä–æ–≥–µ',\n",
       "   '—Ç–≤–æ—Ä–∏—Ç—Å—è',\n",
       "   ',',\n",
       "   '–≤—Å–µ',\n",
       "   '–µ–¥—É—Ç',\n",
       "   ',',\n",
       "   '–∫–∞–∫',\n",
       "   '—Ö–æ—Ç—è—Ç',\n",
       "   ',',\n",
       "   '–∫—É–¥–∞',\n",
       "   '—Ö–æ—Ç—è—Ç',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.',\n",
       "   '–Ω–∏–∫–∞–∫–æ–≥–æ',\n",
       "   '—É–≤–∞–∂–µ–Ω–∏—è',\n",
       "   '–¥—Ä—É–≥',\n",
       "   '–∫',\n",
       "   '–¥—Ä—É–≥—É',\n",
       "   '‚Ä¶']],\n",
       " [['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['''–•–æ—á–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Ç–∞–∫–∏–º –≤–æ–¥–∏—Ç–µ–ª—è–º...\n",
    "–ß—Ç–æ –¥–≤–∏–∂–µ—Ç –≤–∞–º–∏ –Ω–∞ –ø—É—Å—Ç–æ–π –¥–æ—Ä–æ–≥–µ? –î–≤–∞–∂–¥—ã –Ω–∞ –∫—Ä–∞—Å–Ω—ã–π –∑–∞ 1 –º–∏–Ω—É—Ç—Éü§¶üèª‚Äç‚ôÇ\n",
    "–¢–∞–∫–æ–π –±–µ—Å–ø—Ä–µ–¥–µ–ª –Ω–∞ –¥–æ—Ä–æ–≥–µ —Ç–≤–æ—Ä–∏—Ç—Å—è, –≤—Å–µ –µ–¥—É—Ç, –∫–∞–∫ —Ö–æ—Ç—è—Ç, –∫—É–¥–∞ —Ö–æ—Ç—è—Ç... –Ω–∏–∫–∞–∫–æ–≥–æ —É–≤–∞–∂–µ–Ω–∏—è –¥—Ä—É–≥ –∫ –¥—Ä—É–≥—É‚Ä¶'''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:16<00:00,  6.12it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('data/pavlov.txt', 'w')\n",
    "for i in tqdm(list(df['text'])):\n",
    "    s = ''\n",
    "    tok = i.split(' ')\n",
    "    try:\n",
    "        if len(tok) < 100:\n",
    "            res = ner_model([i])\n",
    "            for j in range(len(res[1][0])):\n",
    "                if res[1][0][j] == 'B-LOC':\n",
    "                    s += res[0][0][j] + ' '\n",
    "            f.write(s + '\\n')\n",
    "        else:\n",
    "            res = ner_model([\" \".join(tok[:100])])\n",
    "            for j in range(len(res[1][0])):\n",
    "                if res[1][0][j] == 'B-LOC':\n",
    "                    s += res[0][0][j] + ' '\n",
    "            f.write(s + '\\n')\n",
    "    except:\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pavlov = []\n",
    "f = open('data/pavlov.txt', 'r')\n",
    "pavlov = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pavlov'] = pavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/new_with_street.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–±–æ–≤–∞–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Yargy/Natasha, –Ω–æ —Ö–æ—Ä–æ—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stop_words = stopwords.words(\"russian\")\n",
    "\n",
    "def process_text(text):\n",
    "    tok = text.split(' ')\n",
    "    pattern = re.compile(\"[–ê-—è+0-9-]+\")\n",
    "    words = pattern.findall(\" \".join(tok))\n",
    "    tokens = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address(parts=[Settlement(name='–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', type=None), Street(name='–ü–ª–∞–Ω–µ—Ä–Ω–∞—è', type='—É–ª–∏—Ü–∞'), Building(number='5', type=None)])\n"
     ]
    }
   ],
   "source": [
    "extractor = AddressExtractor()\n",
    "sample = process_text(text)\n",
    "matches = extractor(text)\n",
    "for match in matches:\n",
    "    print(match.fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. –≠–≤–∞–∫—É–∏—Ä–æ–≤–∞–ª–∏ 384 –ª–∏—Ü–µ–π. (–≤ 14:30 –≤—Å–µ—Ö –∑–∞–ø—É—Å—Ç–∏–ª–∏ –Ω–∞–∑–∞–¥) \\n2. –≠–≤–∞–∫—É–∏—Ä–æ–≤–∞–ª–∏ –≥–∏–º–Ω–∞–∑–∏—é 405\\n3. –í 14:00 —ç–≤–∞–∫—É–∏—Ä–æ–≤–∞–ª–∏ 98 —à–∫–æ–ª—É\\n4. –≠–≤–∞–∫—É–∏—Ä–æ–≤–∞–ª–∏ –≥–∏–º–Ω–∞–∑–∏—é 399\\n5. –≠–≤–∞–∫—É–∏—Ä–æ–≤–∞–ª–∏ –≥–∏–º–Ω–∞–∑–∏—é 41\\n6. 295 –≥–∏–º–Ω–∞–∑–∏—é —ç–≤–∞–∫—É–∏—Ä—É—é—Ç.\\n\\n–≠–≤–∞–∫—É–∏—Ä–æ–≤–∞–ª–∏ —É—á–∞—â–∏—Ö—Å—è –∏–∑ —à–∫–æ–ª—ã ‚Ññ 553 –§—Ä—É–Ω–∑–µ–Ω—Å–∫–æ–≥–æ —Ä–∞–π–æ–Ω–∞ –Ω–∞ —É–ª–∏—Ü–µ –Ø—Ä–æ—Å–ª–∞–≤–∞ –ì–∞—à–µ–∫–∞, 4, –∫–æ—Ä–ø. 4'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6797ffe8456341968698664d2c13bde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58123), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "f = open('data/street_from_natasha.txt', 'w')\n",
    "extractor = AddressExtractor()\n",
    "for i in tqdm(list(df['text'])):\n",
    "    sample = process_text(i)\n",
    "    matches = extractor(sample)\n",
    "    s = ''\n",
    "    for match in matches:\n",
    "        for j in range(0, len(match.fact.parts)):\n",
    "            try:\n",
    "                if match.fact.parts[j].type is None:\n",
    "                    try:\n",
    "                        s += match.fact.parts[j].number + ' '\n",
    "                        continue\n",
    "                    except:\n",
    "                        s += match.fact.parts[j].name + ' '\n",
    "                        continue\n",
    "                try:\n",
    "                    if match.fact.parts[j].number is None:\n",
    "                        break\n",
    "                    s += match.fact.parts[j].type + ' ' + match.fact.parts[j].number + ' '\n",
    "                except:\n",
    "                    if match.fact.parts[j].name is None:\n",
    "                        continue\n",
    "                s += match.fact.parts[j].type + ' ' + match.fact.parts[j].name + ' '\n",
    "            except:\n",
    "                continue\n",
    "    f.write(s + '\\n')\n",
    "    if len(matches)>0:\n",
    "        k += 1\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
